{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "# Always make it pretty.\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.drop('price',axis=1)\n",
    "train_target = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from math import sqrt\n",
    "def train_test_model(clf, X, y, cv=5):\n",
    "    # Fit a model by providing X and y from training set\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/cv, random_state=0)\n",
    "    score = cross_validate(clf,X,y,scoring='neg_mean_squared_error',cv=cv,return_train_score=True)\n",
    "    test_list = score['test_score']\n",
    "    train_list = score['train_score']\n",
    "    for i in range(len(test_list)):\n",
    "        test_list[i] = sqrt(-test_list[i])\n",
    "    for i in range(len(train_list)):\n",
    "        train_list[i] = sqrt(-train_list[i])\n",
    "    train_score = train_list\n",
    "    test_score = test_list\n",
    "    \n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 35.46869199189682 0.26590895683867993\n",
      "Test score 53.74684643169652 1.2850655517634635 [55.99622714 53.02469717 54.34957693 52.53337097 52.83035995]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "\n",
    "parameters = {'n_estimators': 1000,\n",
    "              'max_features': 'sqrt',\n",
    "#               'criterion': 'gini',\n",
    "              'learning_rate':0.008,\n",
    "              'max_depth': 10,\n",
    "              'min_samples_split': 10,\n",
    "              'min_samples_leaf': 8,\n",
    "              'random_state': 5,\n",
    "              'subsample': 0.8\n",
    "#               'n_jobs': -1\n",
    "              }\n",
    "\n",
    "clf = GradientBoostingRegressor(**parameters)\n",
    "\n",
    "# Fit a model by providing X and y from training set\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "train_score, test_score = train_test_model(clf, X, y, 5)\n",
    "print('Train score',train_score.mean(),train_score.std())\n",
    "print('Test score',test_score.mean(),test_score.std(),test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([20.79545242, 20.9693256 , 20.93930035, 21.17854883, 21.25123316]), array([58.46614801, 57.241918  , 57.83155773, 56.16246299, 55.62157964]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "#               'base_estimator':base_classifier,\n",
    "              'n_estimators': 500,\n",
    "              'n_jobs': -1\n",
    "              }\n",
    "\n",
    "clf = BaggingRegressor(**parameters)\n",
    "\n",
    "# Train test model\n",
    "train_score, test_score = train_test_model(clf, X, y, 5)\n",
    "print('Train score',train_score.mean(),train_score.std())\n",
    "print('Test score',test_score.mean(),test_score.std(),test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 45.98462174258526 0.2847606787828057\n",
      "Test score 57.359534773054904 1.0518318712832666 [59.01739119 56.68527233 58.18650308 56.50758866 56.40091861]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "\n",
    "parameters = {'n_estimators': 1000,\n",
    "              'max_features': 'sqrt',\n",
    "#               'criterion': 'gini',\n",
    "              'max_depth': 20,\n",
    "              'min_samples_split': 5,\n",
    "              'min_samples_leaf': 5,\n",
    "              'random_state': 0,\n",
    "              'n_jobs': -1\n",
    "              }\n",
    "\n",
    "clf = RandomForestRegressor(**parameters)\n",
    "\n",
    "# Fit a model by providing X and y from training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "train_score, test_score = train_test_model(clf, X, y, 5)\n",
    "print('Train score',train_score.mean(),train_score.std())\n",
    "print('Test score',test_score.mean(),test_score.std(),test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 61.716890969412056 1.8102900116963663\n",
      "Test score 62.66336591432156 2.6117215310663404 [64.05377628 66.32367832 62.90758956 58.48350161 61.5482838 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "    'solver':'adam', \n",
    "    'activation':'relu',\n",
    "    'alpha':1e-3, #increase alpha->increase penalty :: http://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py\n",
    "    'hidden_layer_sizes':(200,200), \n",
    "    'learning_rate':'adaptive',\n",
    "    'random_state':1\n",
    "    }\n",
    "clf = MLPRegressor(**parameters)\n",
    "\n",
    "# Train test model\n",
    "train_score, test_score = train_test_model(clf, X, y, 5)\n",
    "print('Train score',train_score.mean(),train_score.std())\n",
    "print('Test score',test_score.mean(),test_score.std(),test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 64.292291383111 0.3904127689392621\n",
      "Test score 100.30344953511197 1.3237747735206835 [100.78473043 102.45565268  98.7457734   99.09724463 100.43384653]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {\n",
    "#     'probability':True, # get simulated probability\n",
    "#     'max_iter':2000,\n",
    "    'kernel':'rbf',\n",
    "    'C':100,\n",
    "    'cache_size':2000,\n",
    "    'gamma': 'auto',\n",
    "    'epsilon': 10\n",
    "    }\n",
    "clf = SVR(**parameters)    \n",
    "\n",
    "# Train test model\n",
    "train_score, test_score = train_test_model(clf, X, y, 5)\n",
    "print('Train score',train_score.mean(),train_score.std())\n",
    "print('Test score',test_score.mean(),test_score.std(),test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf = SVR()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "param_grid = {\n",
    "#     'probability':True, # get simulated probability\n",
    "#     'max_iter':[2000],\n",
    "    'kernel':['rbf'],\n",
    "    'C':[5,10],\n",
    "    'cache_size':[2000],\n",
    "    'gamma': ['auto'],\n",
    "    'epsilon':[1,5]\n",
    "    }\n",
    "\n",
    "# param_grid = {'n_estimators': [100,200], \n",
    "#               'max_features': ['auto'], \n",
    "#               'criterion': ['gini'],\n",
    "#               'max_depth': [15,20,25], \n",
    "#               'min_samples_split': [2],\n",
    "#               'min_samples_leaf': [2,10,20],\n",
    "#               'n_jobs':[-1]\n",
    "#              }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "# acc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Run the grid search\n",
    "# read theory\n",
    "grid_obj = GridSearchCV(clf, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_obj = grid_obj.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)\n",
    "y_train_pred,y_test_pred = train_test_model(clf, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=10, cache_size=2000, coef0=0.0, degree=3, epsilon=5, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse: 19.421791661412776\n",
      "test rmse: 54.59892522564553\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "rss = 0\n",
    "y_train = np.array(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    rss += (y_train[i] - y_train_pred[i])**2\n",
    "mse = rss/len(y_train)\n",
    "rmse = sqrt(mse)\n",
    "print('train rmse:',rmse)\n",
    "\n",
    "rss = 0\n",
    "y_test = np.array(y_test)\n",
    "for i in range(len(y_test)):\n",
    "    rss += (y_test[i] - y_test_pred[i])**2\n",
    "mse = rss/len(y_test)\n",
    "rmse = sqrt(mse)\n",
    "print('test rmse:',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_data = pd.read_csv('cleaned_score_data.csv')\n",
    "X_train = X\n",
    "y_train = y\n",
    "X_test = score_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "\n",
    "parameters = {'n_estimators': 1000,\n",
    "              'max_features': 'sqrt',\n",
    "#               'criterion': 'gini',\n",
    "              'learning_rate':0.008,\n",
    "              'max_depth': 10,\n",
    "              'min_samples_split': 10,\n",
    "              'min_samples_leaf': 8,\n",
    "              'random_state': 5,\n",
    "              'subsample': 0.8\n",
    "#               'n_jobs': -1\n",
    "              }\n",
    "\n",
    "\n",
    "clf = GradientBoostingRegressor(**parameters)\n",
    "\n",
    "# Fit a model by providing X and y from training set\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# Train test model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on the training data\n",
    "y_train_pred = clf.predict(X_train)\n",
    "#     p_train_pred = clf.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse: 36.4506108575449\n"
     ]
    }
   ],
   "source": [
    "rss = 0\n",
    "y_train = np.array(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    rss += (y_train[i] - y_train_pred[i])**2\n",
    "mse = rss/len(y_train)\n",
    "rmse = sqrt(mse)\n",
    "print('train rmse:',rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_id = pd.read_csv('scoringData.csv')['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([airbnb_id,pd.DataFrame(y_test_pred)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id       price\n",
      "0  4989  191.501664\n",
      "1  5054  173.623697\n",
      "2  5136  260.050912\n",
      "3  6090  211.223864\n",
      "4  6990   71.374649\n"
     ]
    }
   ],
   "source": [
    "result.columns=['id','price']\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"airbnb6.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
